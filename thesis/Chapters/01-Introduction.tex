\chapter[Introduction]{Introduction}
\label{cp:introduction}

{
	\parindent0pt
	This chapter introduces some fundamental concepts necessary to understand Molecular Dynamics (MD) simulations. We begin with a discussion of the motivation behind the general $n$-body problem and the goals of this thesis in \autoref{sec:motivation}.
	Afterwards, the components of a simple MD simulation loop are presented in \autoref{sec:md}. These include Newton’s laws of motion for providing the governing equations of particle trajectories, the Lennard-Jones potential as a model for pairwise interactions, and the Störmer-Verlet algorithms as a numerical scheme for integrating the equations of motion.
}


% TODO: check atomic/molecular interactions

\section{Motivation}
\label{sec:motivation}

The $n$-body problem is a foundational challenge of classical physics. It  concerns the interaction and movement of bodies, like the trajectories of masses in the solar system. At such astronomic scales, general relativity additionally introduces a high degree of complexity. Yet, even in classical Newtonian physics, the systems of equations tend to no longer be solvable by analytic means if $n>2$ bodies are involved, except for certain special cases. Hence, numerical algorithms have become essential in finding approximate solutions. \cite{Arnold1985}

With the advent of computer-based simulation, the feasibility of numerical solutions to the $n$-body problem has increased significantly.
Over the past few decades, advances in high performance computing (HPC) have further increased both scale and efficiency of such simulations, allowing for the modeling of large systems at unprecedented resolution. For instance, the TianNu project simulated \num{2.97e12} particles in 2017 on the Tianhe-2 supercomputer \cite{Emberson2017}.
These days, particle simulations have established themselves as indispensable tools across a wide range of scientific fields. Applications reach from drug discovery \cite{Hollingsworth2018} to plasma physics \cite{Verboncoeur2005} and materials science \cite{Parteli2016}.

One example of a software framework enabling $n$-body simulations is the AutoPas library \cite{Gratl2019}. Its internal mechanisms will be discussed in detail in \autoref{cp:autopas}; for the motivation of this thesis it suffices to know, that AutoPas seeks to dynamically select optimal simulation configurations without requiring expert knowledge during setup (\enquote{autotuning}).

To achieve this, so-called tuning phases are initiated at fixed intervals. During each tuning phase, different configurations are sampled for a predetermined number of iterations, after which the best performing configuration is selected to simulate the remaining iterations until the next tuning phase. Naturally, these static intervals do not necessarily align with the points at which it would be most advantageous to switch configurations. Consider a scenario, in which the optimal configuration changes rapidly in the beginning, but stabilizes and settles into an equilibrium later on. Having one uniform static interval, it would be either too short --- resulting in unnecessary tuning phases during equilibrium, or too long --- resulting in suboptimal performance in the early phase.
This thesis proposes a method to resolve this problem by dynamically initiating tuning phases based on live simulation data.

% TODO: dynamic intervals figure?

\section{Molecular Dynamics}
\label{sec:md}
% quantum behaviour
Molecular Dynamics (MD) simulation is one method of solving the classical $n$-body problem on the molecular level. At that level, the interactions between atoms are subject to the of laws quantum mechanics, in particular the Schrödinger equation. That equation however is unsuitable for the simulation of larger systems due to its complexity by nature of being a partial differential equation.

Therefore, simplifications such as the Born-Oppenheimer approximation have to be employed. This approximation is based on the fact that the nuclei of atoms have much greater mass than the electrons surrounding them. Under the additional assumption, that the nuclei can be considered static relative to the movements of the electrons, we can separate the Schrödinger equation into two parts coupled by an interaction potential. Using further simplifications, we obtain \eqref{eq:born_oppenheimer}, which directly corresponds to the classical laws of motion as stated by Newton (cf. \autoref{sec:newton}). In this equation, $\vb p_i(t), \vb a_i(t), m_i, V\left(\vb p_i(t)\right)$ are the position, acceleration, mass and potential acting on a particle $i$ at time $t$. \cite{Born1927, Voorhis2005, Griebel2007} 

\begin{equation}
	m_i\vb a_i(t) = -\nabla_{\vb p_i} V\left(\vb p(t)\right)\label{eq:born_oppenheimer}
\end{equation}

The simplest interatomic potentials one could apply here describe the interactions between only two particles, such as the Gravitational, Lennard-Jones or Coloumb potentials. \cite{Griebel2007}

Considering the formula presented in \eqref{eq:born_oppenheimer}, the main MD simulation loop is rather simple. It consists of calculating the forces between particles or atoms and integrating the equations of motion. These two steps are repeated until an equilibrium is reached, at which point the desired measurements can be taken. \cite{Frenkel2002}





\subsection{Newton's Laws of Motion}
\label{sec:newton}
As referred to before, Newton's laws of motion can be applied to MD simulation in approximating particle behavior. These well-known laws of classical mechanics are as follows. \cite{Newton1934}
\begin{enumerate}[label=\Roman*.]
	\item \textit{Every object perseveres in its state of rest, or of uniform motion in a right line, unless it is compelled to change that state by forces impressed thereon.}

	      In other words, if the net force on any body is zero, its velocity is constant.
	\item \textit{The alteration of motion is ever proportional to the motive force impressed; and is made in the direction of the right line in which that force is impressed.}

	      In other words, $F=m\cdot a$.
	\item \textit{To every action there is always opposed an equal reaction: or, the mutual actions of two bodies upon each other are always equal, and directed to contrary parts.}

	      In other words, if one body exerts force $F_a$ on another body, than the second body exerts force $F_b=-F_a$ on the first body.
\end{enumerate}

The second law is of utmost importance, as it allows to compute trajectories of particles based on the force acting upon them. The third law, while secondary in dynamics, is useful especially regarding optimizations: for pairwise interactions, the force needs to be evaluated only once, since the second particle experiences a force of the same magnitude in opposed direction. \cite{Gratl2021}

% TODO: ref to Newton3 optimization

\subsection{Lennard-Jones Potential}
\label{sec:lj_potential}
Simulating all pairwise interactions between atoms has complexity $\mathcal{O}\left(n^2\right)$. To reduce this complexity, most MD simulations restrict themselves to short-range interactions. As the forces of these interactions are negligible if the interacting particles are far apart, a cutoff-radius can be introduced after which the forces can be assumed to be close to zero. This significantly reduces the computational complexity, as only the interactions between close neighbors have to be computed. \cite{Gratl2021}

The Lennard-Jones (LJ) potential is one such short-range interaction potential that acts on pairs of particles. It is based on empirical data and a sufficiently good approximation such that macroscopic effects can be derived from simulating the interactions at an atomic level.
It is most frequently used in the form of the 12-6 potential as defined in \eqref{eq:lj_12_6}.

\begin{equation}
	V_{\text{LJ}}(r)=4\varepsilon\left[\left(\frac{\sigma}{r}\right)^{12}-\left(\frac{\sigma}{r}\right)^{6}\right]\label{eq:lj_12_6}
\end{equation}

In this equation, $r$ is the distance between the two particles, $\varepsilon$ the interaction strength and $\sigma$ the distance at which the potential signs change (zero-crossing). Parameters $\varepsilon, \sigma$ are dependent on the simulation context, e.g. the material which ought to be simulated. The potential function is illustrated in \autoref{fig:lj_graph}. \cite{Wang2020, Lenhard2024}


\begin{figure}[htpb]
	\centering
	\begin{tikzpicture}
		\begin{axis}[height=0.4\textwidth, width=0.6\textwidth,
			xmin = 0.75,
			xmax = 3.25,
			ymin = -1.25,
			ymax = 2.25,
			xlabel={Distance $r$ between particles},
			ylabel={Potential $V_{\text{LJ}}$},
			xtick={{2^(1/6)},1.5,2,2.5,3},
			xticklabels={$r_\text{min}$,1.5$\sigma$,2$\sigma$,2.5$\sigma$,3$\sigma$},
			ytick={-1, 0, 1, 2},
			yticklabels={$-\varepsilon$,0,$\varepsilon$,2$\varepsilon$},
			clip=false]
			\addplot [
				color=chaptertumblue, very thick,
				domain=0.95:3,
				samples=400,
			]
			{4*((1/x)^(12) - (1/x)^6)};
			\draw[black!80] (axis cs:0.75,0) -- (axis cs:3.25,0);
			\draw[black!80] (axis cs:{2^(1/6)},2.25) -- (axis cs:{2^(1/6)},-1.25);
			\draw[black!80, dashed] (axis cs:0.75,-1) -- (axis cs:{2^(1/6)},-1);
			\draw [decorate,decoration={brace, amplitude=1ex, raise=0.5ex}] (axis cs:0.75,2.25) -- (axis cs:{2^(1/6)-0.0125},2.25) node[midway, yshift=2.5ex]{Attraction\vphantom{p}};
			\draw [decorate,decoration={brace, amplitude=1ex, raise=0.5ex}] (axis cs:{2^(1/6)+0.0125},2.25) -- (axis cs:3.25,2.25) node[midway, yshift=2.5ex]{Repulsion};
		\end{axis}
	\end{tikzpicture}
	\caption{An illustration of the potential well of the 12-6 LJ potential, with the minimum of $-\varepsilon$ at $r_\text{min}=\sigma\sqrt[6]{2}$ and zero-crossing at $\sigma$. The figure is based on Lenhard et al. \cite{Lenhard2024}}
	\label{fig:lj_graph}
\end{figure}

% TODO: mark r=1\sigma as zero-crossing point

\subsection{Störmer-Verlet Algorithm}
\label{sec:stoermer_verlet}
Using LJ potentials and Newton's laws of motion, we can construct a system of ordinary differential equations. To solve them analytically is practically infeasible for large systems, therefore numeric solvers have to be used in approximating a solution, as stated before.

% TODO: symplectic integrator, good macroscopic simulation
The Störmer-Verlet algorithm is one such numeric technique for solving the systems constructed as mentioned.
With $\vb p_i(t), \vb v_i(t), \vb a_i(t), m_i, \vb F_i(t)$ as the position, velocity, acceleration, mass and force acting on a particle $i$ at time $t$, we can derive the algorithm by the summation of Taylor expansions. First, we deduce the position of particle $i$ at time $t+\delta t$, as in \eqref{eq:pos_taylor_forward}. Secondly, we take a backwards step to $t-\delta t$, as in \eqref{eq:pos_taylor_backward}.
\begin{equation}
	\vb p_i(t+\delta t) = \vb p_i(t)+\delta t\dot{\vb p}_i(t)+\frac{1}{2}\delta t^2\ddot{\vb p}_i(t)+\frac{1}{6}\delta t^3\dddot{\vb p}_i(t)+\mathcal{O}(\delta t^4)\label{eq:pos_taylor_forward}
\end{equation}
\begin{equation}
	\vb p_i(t-\delta t) = \vb p_i(t)-\delta t\dot{\vb p}_i(t)+\frac{1}{2}\delta t^2\ddot{\vb p}_i(t)-\frac{1}{6}\delta t^3\dddot{\vb p}_i(t)+\mathcal{O}(\delta t^4)\label{eq:pos_taylor_backward}
\end{equation}

By adding both \eqref{eq:pos_taylor_forward} and \eqref{eq:pos_taylor_backward} and reordering terms, we conclude \eqref{eq:pos_verlet}.
\begin{equation}
\vb p_i(t+\delta t) = 2\vb p_i(t) - \vb p_i(t-\delta t) + \delta t^2\ddot{\vb p}_i(t) + \mathcal{O}(\delta t^4)\label{eq:pos_verlet}
\end{equation}

As the second derivative of the position $\vb p_i(t)$ is the acceleration $\vb a_i(t)$, we can express \eqref{eq:pos_verlet} as \eqref{eq:acc_verlet}. Where, by Newton's second law, $\vb a_i(t) = \frac{\vb F_i(t)}{m_i}$.
\begin{equation}
	\vb p_i(t+\delta t) = 2\vb p_i(t) - \vb p_i(t-\delta t) + \delta t^2{\vb a}_i(t) + \mathcal{O}(\delta t^4)\label{eq:acc_verlet}
\end{equation}

By this formulation we could already calculate the velocities of the particles, however, there are some drawbacks -- e.g. high error propagation. A more exact and efficient approach, sometimes referred to as the Velocity-Verlet algorithm, can be derived similarly.
For that, considering \eqref{eq:velocity}, we can rearrange and substitute into \eqref{eq:pos_verlet} to conclude \eqref{eq:verlet_pos2} and finally \eqref{eq:verlet_vel}.
\begin{equation}
	\vb v_i(t) = \frac{\vb p_i(t+\delta t) -\vb p_i(t-\delta t)}{2\delta t} \rightsquigarrow \vb p_i(t-\delta t)= \vb p_i(t+\delta t)-2\delta t \vb v_i(t) \label{eq:velocity}
\end{equation}

\begin{equation}
	\vb p_i(t+\delta t) = \vb p_i(t) +\delta t \vb v_i(t) + \frac{\delta t^2}{2}{\vb a}_i(t) + \mathcal{O}(\delta t^4) \label{eq:verlet_pos2}
\end{equation}
\begin{equation}
	\vb v_i(t+\delta t) = \vb v_i(t)+\frac{\delta t}{2}\left[\vb a_i(t)+ \vb a_i(t+\delta t)\right] + \mathcal{O}(\delta t^4) \label{eq:verlet_vel}
\end{equation}
Because of the aforementioned improved properties of this method, it is often preferred in MD simulations. \cite{Fulst2013, Leimkuhler2005, Hairer2003}

% TODO: refer to experiments done in md-flexible
% md-flexible is a simple molecular dynamics simulation built around AutoPas. It simulates the Lennard-Jones 12-6 potential on single-site particles with Störmer- Verlet time integration. 



